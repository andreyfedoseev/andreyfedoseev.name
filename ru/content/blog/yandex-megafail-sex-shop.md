Title: Про Яндекс, megafail и секс-шоп
Date: 2011-07-25T15:54:00
Slug: 44/yandex-megafail-sex-shop
Feed: false

Все уже слышали про [megafail](http://lenta.ru/news/2011/07/18/megafail/). А теперь вот случился [секс-шоп-фейл](http://internet.cnews.ru/news/top/index.shtml?2011/07/25/448674). Это вообще жесть, там даже домашние адреса указаны.

Конечно, создатели сайта, а точнее движка электронного магазина — идиоты. Об этом свидетельствует хотя бы URL, начинающийся с index.php.

Но я считаю, что вина Яндекса тут тоже есть. Яндекс говорит, что мол надо было указывать нужные правила в файле robots.txt. А что такое robots.txt? Это просто некая договорённость. И соблюдать её никто не обязан.

Вот, например, делаю я сайт. Или даже не я, а какой-то ПХПшник. И он не знает про файл robots.txt. А может быть он ночью под одеялом разрабатывает свой альтернативный «стандарт» bots.txt и не использует robots.txt из вредности. Но сути это не меняет. А суть в том, что создавать этот файл он не обязан.

<!-- more -->

Допустим, что этот ПХПшник решил реализовать некую функцию, которая связана с отображанием конфиденциальной информации, но при этом он не хочет делать принудительную авторизацию пользователей (думает об удобстве, ок). На помощь приходят «секретные» ссылки. Эти ссылки содержат в себе некий ключ, который по сути является паролем. Соответственно, доступ к странице может получить только тот, у кого есть эта ссылка. Кстати, «секретные» ссылки используют не только ПХПшники, но даже Гугль! При этом можно сказать, что сама ссылка тоже является конфиденциальной информацией. И поскольку эта информация конфиденциальна, то ПХПшник нигде на сайте её не показывает.

Вернёмся к поиску Яндекса. Яндекс ходит по интернету, загружает страницы, индексирует их и показывает в результатах поиска. Вопрос: откуда он узнаёт адреса страниц? Теоретически он, как и любой другой добросовестный пользовать интернета, должен искать ссылки на уже просмотренных страницах. Об этом, кстати, говорится в «[Лицензии на использование поисковой системы Яндекса](http://company.yandex.ru/legal/termsofuse)»:

> 4.2. Яндекс индексирует открытую часть интернета — те страницы, которые *доступны при переходе по ссылке*, без ввода логина и пароля, и индексирование которых не запрещено в robots.txt соответствующего сайта.

Размещал ли ПХПшник конфиденциальные ссылки на своём сайте? Может быть он и идиот, но не настолько. Откуда же Яндекс их взял. Говорят, что собрал через скрипт Яндекс.Метрики. Вот, что написано в «Пользовательском соглашение Яндекс.Метрики»:

> Яндекс […] не осуществляет никаких целенаправленных действий по сбору, получению, обработке и распространению чьих-либо персональных данных в результате использования Сервиса Пользователем.

Ок, но если URL сам по себе является персональными данными? Я готов смириться с тем, что они их собирают. Но они же их и распространяют, таким образом нарушая собственное соглашение. Буквоеды могут заткнуться насчёт того, что «конфиденциальные» и «персональные» это не одно и то же. В данном случае мне плевать.

Получается, что Яндекс под прикрытием невинного счётчика, распространяет вредоносное ПО, которое собирает и потом распространяет конфиденциальные данные! Я, конечно, утрирую. Я уверен, что Яндекс не осуществлял «никаких целенаправленных действий по сбору, получению, обработке и распространению». Это были нецеленаправленные действия. Короче говоря, оно само.

<small>P.S. Я, в целом, хорошо отношусь к деятельности Яндекса. Но тут они, по-моему, в какашку наступили.</small>

**Обновлено**: Вот тут [Яндекс](http://webmaster.ya.ru/replies.xml?item_no=10941) рассказывает, что адреса «секретных» ссылок могут быть известны интернет-провайдерам, сотрудникам спецслужб, плагинам браузера.

> […] теперь можно сказать, что почти весь мировой интернет знает про существование этой ссылки.

А значит и Яндексу можно их знать и публиковать!
